{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos todas las librerias\n",
    "import numpy as np\n",
    "import h5py\n",
    "import copy\n",
    "import glob\n",
    "import datetime as dt\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos el grid para la region\n",
    "latmin = 13\n",
    "latmax = 34\n",
    "lonmin = -119\n",
    "lonmax = -73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicializacion del tiempo para convertir TAI93 a epoch\n",
    "t0=dt.datetime.utcfromtimestamp(0.0)                      # 1970-1-1 00:00:00\n",
    "t93=dt.datetime(1993,1,1,0,0,0,0)                         # 1993-1-1 00:00:00\n",
    "t93secs=(t93-t0).total_seconds()                          # segundos de 1970 a 1993"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtiene las variables del archivo de texto (abre, copia a lista, y cierra)\n",
    "vartxt = open('targetvariables.txt','r')\n",
    "variables = vartxt.read().replace('\\n','')\n",
    "vartxt.close()\n",
    "# print(variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tomado de read_oco2_co2_nc4.py de D3_SATELITE en EPR03 y modificado un poco\n",
    "\n",
    "fields = []                                      # se inicializa la lista fields\n",
    "for ele in variables.split(\"\\\\\"):                # divide variables en elementos separados por linea (\\)\n",
    "    trozos = tuple(ele.split(\",\"))               # genera tuples que contienen como elemento trozos de cada linea \n",
    "    #print(trozos)\n",
    "    tupla = []                                   # inicia la lista que se agregara como tuple a fields\n",
    "    for ii,ele in enumerate(trozos):            \n",
    "        if ii == 2:\n",
    "            tupla.append(int(ele.strip()))       # si trozos tiene tres elementos, agrega el tercero como int\n",
    "        else:                                    # strip() elimina los espacios vacios\n",
    "            tupla.append(ele.strip())            # los dos primeros elementos del tuple trozos se agregan a la lista tupla \n",
    "    fields.append(tuple(tupla))                  # agrega el la lista tupla como tuple a fields\n",
    "# print(fields)\n",
    "target_hdf_tipos=np.dtype(fields)                # genera la estructura para crear la matriz\n",
    "# print(tipos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onebyone(mat_target,fh5):\n",
    "    \"\"\"\n",
    "    Recibe la matriz de mediciones filtradas por processlist y el archivo h5 donde se va a escribir las mediciones\n",
    "    Escribe las mediciones por latitud y longitud en el archivo h5\n",
    "    Original de read_oco2_co2_nc4.py \n",
    "    \"\"\"\n",
    "\n",
    "    for ii,line in enumerate(mat_target):\n",
    "\n",
    "        lat = line[\"/latitude\"]                                  # toma el valor de latitud de la linea\n",
    "        lon = line[\"/longitude\"]                                 # toma el valor de longitud de la linea\n",
    "\n",
    "        # try/except intenta abrir la seccion xN-yW del hdf creado y agrega la linea, si no hay seccion entonces crea una\n",
    "        try:\n",
    "            dset=fh5['%iN%iW' % (int(lat),int(lon))]             # toma el grid del hdf casero donde debería ir el dato\n",
    "            n=dset.shape[0]                                      # obtiene el tamaño\n",
    "            dset.resize((n+1,))                                  # le suma un elemento al tamaño \n",
    "            dset[n]=line                                         # le pone la linea al ultimo espacio \n",
    "            fh5.flush()                                          # escribe en disco \n",
    "        except:\n",
    "            datalatlon=[line]                                    # crea una lista con los datos de la linea\n",
    "            # try/except intenta crear un dataset, si fall entonces muestra un mensaje\n",
    "            try:\n",
    "                # crea un dataset xN-yW sin limite (None) tomando la parte entera de lat y lon con los datos de la linea\n",
    "                dset=fh5.create_dataset('%iN%iW' % (int(lat),int(lon)),data=datalatlon,maxshape=(None,))\n",
    "                fh5.flush()                                      # escribe en disco\n",
    "            except:\n",
    "                print('nada works')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processlist(lista,h5filename):\n",
    "    \"\"\"\n",
    "    Recibe una lista de archivos hdf del oco3 target para filtrarlos de acuerdo a \n",
    "    latmin, latmax, lonmin y lonmax y el nombre del archivo h5 de salida\n",
    "    Llama a onebyone\n",
    "    Modificada por Mixtli Campos, Ago-2020\n",
    "    Original de read_oco2_co2_nc4.py \n",
    "    \"\"\"\n",
    "\n",
    "    # esta seccion try/except intenta abrir un archivo hdf existente y si no puede crea uno nuevo\n",
    "    try:\n",
    "        fh5=h5py.File(h5filename,'r+')\n",
    "        print('file exist')\n",
    "    except:\n",
    "        fh5=h5py.File(h5filename,'w')\n",
    "        print('new file')\n",
    "\n",
    "    # este contador ayuda a ver cuantas lineas se agregan\n",
    "    cont = 0\n",
    "    \n",
    "    # esta seccion se encarga de generar una matriz para que la funcion onebyone escriba el hdf \n",
    "    for filename in lista:\n",
    "        #print(filename)\n",
    "        datos=h5py.File(filename,'r')                              # abre el archivo hdf del target\n",
    "        lat = datos[\"/latitude\"][()]                                # vector de latitud\n",
    "        lon = datos[\"/longitude\"][()]                               # vector de longitud\n",
    "        #xco2_qf = datos[\"/xco2_quality_flag\"][()]                  # vector de quality flag (sin usar para target)\n",
    "        \n",
    "        # Lo siguiente es el filtro para latitud, longitud\n",
    "        cond_latlon = ((lat > latmin) & (lat < latmax) & (lon > lonmin) & (lon < lonmax)) \n",
    "        #print(filename,len(lat),len(lat[cond_latlon]))\n",
    "        \n",
    "        # el siguiente if/else crea la matriz mat_inter solo si se cumple la condicion\n",
    "        if len(lat[cond_latlon]) > 0:                 \n",
    "            mat_inter = np.empty(len(lat[cond_latlon]),dtype=target_hdf_tipos) # mat_inter es estructura target_hdf_tipos\n",
    "            for name in target_hdf_tipos.names[1:]:                            # empieza desde 1 porque agregamos tepoch\n",
    "                mat_inter[name] = datos[name][()][cond_latlon]\n",
    "            ### Se suman los segundos de 1970 a 1993 al valor TAI93 del hdf para obtener epoch\n",
    "            mat_inter[\"tepoch\"] = np.array([huh+t93secs for huh in mat_inter[\"/time_tai93\"]])\n",
    "            #mat_inter[\"lat\"] = mat_inter[\"/latitude\"]                         # lat y lon adicionales no se necesitan\n",
    "            #mat_inter[\"lon\"] = mat_inter[\"/longitude\"]                        # para los target hdf\n",
    "            #print(\"mat_inter\",mat_inter.shape)\n",
    "            if cont == 0:\n",
    "                ### SE CREA LA MATRIZ DONDE SE CONCATENAN LOS DIFERENTES DIAS AL INICIO, CUANDO EL CONTADOR ES 0\n",
    "                mat_target = copy.copy(mat_inter)\n",
    "            else:\n",
    "                ### SE CONCATENA LOS VALORES FILTRADOS DE CADA DIA DEL MES A LA MATRIZ mat_target\n",
    "                mat_target = np.concatenate((mat_target,mat_inter),axis=0)\n",
    "            cont = cont+len(lat[cond_latlon])\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "        datos.close()\n",
    "    #print(\"Contador\",cont)\n",
    "    print(\"mat_target\",h5filename,mat_target.shape)\n",
    "    onebyone(mat_target,fh5)  ### SE MANDA LLAMAR onebyone\n",
    "    #zlevels=np.arange(20)\n",
    "    #fh5.attrs.create('zlevels', zlevels, dtype=zlevels.dtype )\n",
    "    fh5.close() ### CIERRA EL ARCHIVO h5 DONDE SE ESCRIBE\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
