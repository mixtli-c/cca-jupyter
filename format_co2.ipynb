{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos todas las librerias\n",
    "import numpy as np\n",
    "import h5py\n",
    "import copy\n",
    "import glob\n",
    "import datetime as dt\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Esta seccion requiere configuracion por parte del usuario\n",
    "\n",
    "# definimos el grid para la region\n",
    "latmin = 13\n",
    "latmax = 34\n",
    "lonmin = -119\n",
    "lonmax = -73\n",
    "\n",
    "# nombre del archivo .txt con las variables\n",
    "archivo_variables = 'd:\\\\gitCCA\\\\cca-jupyter\\\\oco3lite_variables.txt'\n",
    "\n",
    "# nombre de variables de latitud, longitud (e.g. /RetrievalGeometry/latitude) tiempo (e.g /time_tai93)\n",
    "latname = \"/latitude\"\n",
    "lonname = \"/longitude\"\n",
    "timename = \"/time\"\n",
    "\n",
    "# tipo de formato de tiempo en el archivo fuente: 0 - posix, 1 - tai , 2 - date\n",
    "whattime = 0\n",
    "\n",
    "# existe variable de quality flag? 0 - No, 1 - Si\n",
    "qfexists = 1\n",
    "qfname = \"/xco2_quality_flag\"\n",
    "\n",
    "### Fin de la seccion que requiere configuracion por parte del usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicializacion del tiempo para convertir TAI93 a epoch\n",
    "t0=dt.datetime.utcfromtimestamp(0.0)                      # 1970-1-1 00:00:00\n",
    "t93=dt.datetime(1993,1,1,0,0,0,0)                         # 1993-1-1 00:00:00\n",
    "t93secs=(t93-t0).total_seconds()                          # segundos de 1970 a 1993"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtiene las variables del archivo de texto (abre, copia a lista, y cierra)\n",
    "vartxt = open(archivo_variables,'r')\n",
    "variables = vartxt.read().replace('\\n','')\n",
    "vartxt.close()\n",
    "# print(variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tomado de read_oco2_co2_nc4.py de D3_SATELITE en EPR03 y modificado un poco\n",
    "\n",
    "fields = []                                      # se inicializa la lista fields\n",
    "for ele in variables.split(\"\\\\\"):                # divide variables en elementos separados por linea (\\)\n",
    "    trozos = tuple(ele.split(\",\"))               # genera tuples que contienen como elemento trozos de cada linea \n",
    "    #print(trozos)\n",
    "    tupla = []                                   # inicia la lista que se agregara como tuple a fields\n",
    "    for ii,ele in enumerate(trozos):            \n",
    "        if ii == 2:\n",
    "            tupla.append(int(ele.strip()))       # si trozos tiene tres elementos, agrega el tercero como int\n",
    "        else:                                    # strip() elimina los espacios vacios\n",
    "            tupla.append(ele.strip())            # los dos primeros elementos del tuple trozos se agregan a la lista tupla \n",
    "    fields.append(tuple(tupla))                  # agrega el la lista tupla como tuple a fields\n",
    "# print(fields)\n",
    "read_tipos=np.dtype(fields)                # genera la estructura para crear la matriz\n",
    "# print(tipos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onebyone(mat_datos,fh5):\n",
    "    \"\"\"\n",
    "    Recibe la matriz de mediciones filtradas por processlist y el archivo h5 donde se va a escribir las mediciones\n",
    "    Escribe las mediciones por latitud y longitud en el archivo h5\n",
    "    Original de read_oco2_co2_nc4.py \n",
    "    \"\"\"\n",
    "\n",
    "    for ii,line in enumerate(mat_datos):\n",
    "\n",
    "        lat = line[\"lat\"]                                  # toma el valor de latitud de la linea\n",
    "        lon = line[\"lon\"]                                 # toma el valor de longitud de la linea\n",
    "\n",
    "        # try/except intenta abrir la seccion xN-yW del hdf creado y agrega la linea, si no hay seccion entonces crea una\n",
    "        try:\n",
    "            dset=fh5['%iN%iW' % (int(lat),int(lon))]             # toma el grid del hdf casero donde debería ir el dato\n",
    "            n=dset.shape[0]                                      # obtiene el tamaño\n",
    "            dset.resize((n+1,))                                  # le suma un elemento al tamaño \n",
    "            dset[n]=line                                         # le pone la linea al ultimo espacio \n",
    "            fh5.flush()                                          # escribe en disco \n",
    "        except:\n",
    "            datalatlon=[line]                                    # crea una lista con los datos de la linea\n",
    "            # try/except intenta crear un dataset, si fall entonces muestra un mensaje\n",
    "            try:\n",
    "                # crea un dataset xN-yW sin limite (None) tomando la parte entera de lat y lon con los datos de la linea\n",
    "                dset=fh5.create_dataset('%iN%iW' % (int(lat),int(lon)),data=datalatlon,maxshape=(None,))\n",
    "                fh5.flush()                                      # escribe en disco\n",
    "            except:\n",
    "                print('nada works')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processlist(lista,h5filename):\n",
    "    \"\"\"\n",
    "    Recibe una lista de archivos hdf del oco3 target para filtrarlos de acuerdo a \n",
    "    latmin, latmax, lonmin y lonmax y el nombre del archivo h5 de salida\n",
    "    Llama a onebyone\n",
    "    Modificada por Mixtli Campos, Ago-2020\n",
    "    Original de read_oco2_co2_nc4.py \n",
    "    \"\"\"\n",
    "\n",
    "    # esta seccion try/except intenta abrir un archivo hdf existente y si no puede crea uno nuevo\n",
    "    try:\n",
    "        fh5=h5py.File(h5filename,'r+')\n",
    "        print('file exist')\n",
    "    except:\n",
    "        fh5=h5py.File(h5filename,'w')\n",
    "        print('new file')\n",
    "\n",
    "    # este contador ayuda a ver cuantas lineas se agregan\n",
    "    cont = 0\n",
    "    \n",
    "    # esta seccion se encarga de generar una matriz para que la funcion onebyone escriba el hdf \n",
    "    for filename in lista:\n",
    "        #print(filename)\n",
    "        datos=h5py.File(filename,'r')                              # abre el archivo hdf del target\n",
    "        lat = datos[latname][()]                                # vector de latitud\n",
    "        lon = datos[lonname][()]                                # vector de longitud\n",
    "        \n",
    "        if qfexists == 1:\n",
    "            xco2_qf = datos[qfname][()]                  # vector de quality flag (sin usar para target)\n",
    "        \n",
    "        if qfexists == 1:\n",
    "             # Lo siguiente es el filtro para latitud, longitud, y xco2 quality flag\n",
    "            cond_latlon = ((lat > latmin) & (lat < latmax) & (lon > lonmin) & (lon < lonmax) & (xco2_qf == 0))\n",
    "        else:\n",
    "            # Lo siguiente es el filtro para latitud, longitud\n",
    "            cond_latlon = ((lat > latmin) & (lat < latmax) & (lon > lonmin) & (lon < lonmax)) \n",
    "            #print(filename,len(lat),len(lat[cond_latlon]))\n",
    "        \n",
    "        # el siguiente if/else crea la matriz mat_inter solo si se cumple la condicion\n",
    "        if len(lat[cond_latlon]) > 0:                 \n",
    "            \n",
    "            mat_inter = np.empty(len(lat[cond_latlon]),dtype=read_tipos) # mat_inter es estructura target_hdf_tipos\n",
    "            \n",
    "            for name in read_tipos.names[3:]:                            # empieza desde 3 porque agregamos tepoch, lat, lon\n",
    "                mat_inter[name] = datos[name][()][cond_latlon]\n",
    "            \n",
    "            # El siguiente if/elif/else selecciona como se creara \"tepoch\" dependiendo del formato de tiempo del archivo fuente\n",
    "            if whattime == 0:\n",
    "                ### POSIX: El tiempo solamente se copia\n",
    "                mat_inter[\"tepoch\"] = mat_inter[timename]\n",
    "            if whattime == 1:\n",
    "                ### TAI93: Se suman los segundos de 1970 a 1993 al valor TAI93 del hdf para obtener epoch\n",
    "                mat_inter[\"tepoch\"] = np.array([huh+t93secs for huh in mat_inter[timename]])\n",
    "            if:\n",
    "                ### DATE: \n",
    "                mat_inter[\"tepoch\"] = np.array([(dt.datetime(year=huh[0],month=huh[1],day=huh[2],hour=huh[3],minute=huh[4],second=huh[5],microsecond=huh[6]*1000) - to).total_seconds() for huh in mat_inter[timename]])\n",
    "                \n",
    "            mat_inter[\"lat\"] = mat_inter[latname]                         # lat y lon adicionales para preservar un formato\n",
    "            mat_inter[\"lon\"] = mat_inter[lonname]                         # para todos los tipos de archivos\n",
    "            #print(\"mat_inter\",mat_inter.shape)\n",
    "            \n",
    "            if cont == 0:\n",
    "                ### SE CREA LA MATRIZ DONDE SE CONCATENAN LOS DIFERENTES DIAS AL INICIO, CUANDO EL CONTADOR ES 0\n",
    "                mat_datos = copy.copy(mat_inter)\n",
    "            \n",
    "            else:\n",
    "                ### SE CONCATENA LOS VALORES FILTRADOS DE CADA DIA DEL MES A LA MATRIZ mat_target\n",
    "                mat_datos = np.concatenate((mat_datos,mat_inter),axis=0)\n",
    "            \n",
    "            cont = cont+len(lat[cond_latlon])\n",
    "        \n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "        datos.close()\n",
    "    #print(\"Contador\",cont)\n",
    "    print(\"mat_datos\",h5filename,mat_datos.shape)\n",
    "    onebyone(mat_datos,fh5)  ### SE MANDA LLAMAR onebyone\n",
    "    #zlevels=np.arange(20)\n",
    "    #fh5.attrs.create('zlevels', zlevels, dtype=zlevels.dtype )\n",
    "    fh5.close() ### CIERRA EL ARCHIVO h5 DONDE SE ESCRIBE\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
